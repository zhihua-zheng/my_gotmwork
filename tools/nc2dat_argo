#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#
#  Qing Li, 20180322

import argparse
import sys
import numpy as np
import datetime
from netCDF4 import Dataset, date2num, num2date
from gotmtool import nctime_to_datetime, nctime_indices, write_pfl

def main():
    # process the input arguments
    parser = argparse.ArgumentParser(description="""
            Read the Argo profile data in netCDF format and
            output the temperature and salinity profiles in a text
            file in the GOTM input file format. The argument -r RANGE
            set the searching radius in degrees.

            Two date mode:
              1) search for all the profiles covering the starting and ending date
                 if the ending date is set using -de ENDDATE.
              2) search for a single profile within the searching range set by
                 -dr DATERANGE, only work if the ending date is not set.
              """)
    parser.add_argument('-i', '--input', action='store', dest='fname_in',
            metavar='NCFILENAME', required=True, help='Input netCDF filename')
    parser.add_argument('-lat', '--latitude', action='store', dest='lat',
            metavar='LATITUDE', required=True,
            help='Latitude of the requested location (-85, 85)')
    parser.add_argument('-lon', '--longitude', action='store', dest='lon',
            metavar='LONGITUDE', required=True,
            help='Longitude of the requested location (-180, 360)')
    parser.add_argument('-r', '--range', action='store', dest='range',
            metavar='RANGE', required=True,
            help='Range in degrees of the searching radius')
    parser.add_argument('-ds', '--date_start', action='store', dest='date_start',
            metavar='STARTDATE', required=True,
            help='Starting date of input data, in the format of YYYYMMDD')
    parser.add_argument('-de', '--date_end', action='store', dest='date_end',
            metavar='ENDDATE',
            help='Ending date of input data, in the format of YYYYMMDD')
    parser.add_argument('-dr', '--date_range', action='store', dest='date_range',
            metavar='DATERANGE',
            help='Date range in days for searching the initial profiles before or after the starting date')
    parser.add_argument('-ot', '--output_temp', action='store',
            dest='fname_out_temp', metavar='TEMPFILENAME',
            help='Output filename for temperature profile')
    parser.add_argument('-os', '--output_salt', action='store',
            dest='fname_out_salt', metavar='SALTFILENAME',
            help='Output filename for salinity profile')
    parser.add_argument('-maxd', '--max_depth', action='store',
            dest='max_depth', metavar='MAXDEPTH',
            help='Max depth of the profiles')
    parser.add_argument('-dry', '--dry', action='store_true', dest='l_dry_run',
            help='Check the available profiles without outputting them into files')
    parser.add_argument('--version', action='version', version='%(prog)s: 1.1')
    # parsing arguments and save to args
    args=parser.parse_args()

    # check arguments
    fname_in = args.fname_in
    rlat = float(args.lat)
    rlon = float(args.lon)
    dr = float(args.range)
    date_start = args.date_start

    if args.date_end:
        l_single = False
        date_end = args.date_end
    elif args.date_range:
        l_single = True
        date_range = float(args.date_range)
    else:
        parser.print_help()
        sys.exit(1)

    if rlon >= 180:
        rlon = rlon - 360.0

    if rlat > 85.0 or rlat < -85.0 or rlon > 180.0 or rlon < -180.0:
        parser.print_help()
        sys.exit(1)

    if args.fname_out_temp:
        fname_out_temp = args.fname_out_temp
    else:
        fname_out_temp = 'tprof_file.dat'

    if args.fname_out_salt:
        fname_out_salt = args.fname_out_salt
    else:
        fname_out_salt = 'sprof_file.dat'

    if args.max_depth:
        max_depth = float(args.max_depth)
    else:
        max_depth = 500.0

    # read data
    infile = Dataset(fname_in, 'r')
    attlist = infile.ncattrs()

    # read latitude and longitude
    lat = infile.variables['Latitude'][:]
    lon = infile.variables['Longitude'][:]

    # find the indices of points within the search range
    idx_loc = np.where(np.all([lat>=rlat-dr, lat<rlat+dr, lon>=rlon-dr,
        lon<rlon+dr], axis=0))[0]

    # read time
    nctime = infile.variables['time']
    nptime = nctime[idx_loc]

    # check if attributes exist
    t_units = nctime.units
    try:
        t_cal = nctime.calendar
    except AttributeError :
        t_cal = 'standard'

    # get starting and ending indices
    dtformat = '%Y%m%d'
    dt_start = datetime.datetime.strptime(date_start, dtformat)
    dnum_start = date2num(dt_start, units=t_units, calendar=t_cal)
    if l_single:
        # search around starting date
        tmp = dnum_start
        dnum_start = tmp-date_range
        dnum_end = tmp+date_range
        tidx_start = np.searchsorted(nptime, dnum_start, side='right')
        tidx_end = np.searchsorted(nptime, dnum_end, side='left')-1
    else:
        # cover the whole range set by the starting to ending date
        dt_end = datetime.datetime.strptime(date_end, dtformat)
        dnum_end = date2num(dt_end, units=t_units, calendar=t_cal)
        tidx_start = np.searchsorted(nptime, dnum_start, side='left')-1
        tidx_end = np.searchsorted(nptime, dnum_end, side='right')

    # check if any profiles are found
    if tidx_end < tidx_start:
        # no message if dry run
        if not args.l_dry_run:
            print("Profile not available. Skip.")
        sys.exit(1)

    # time in datetime format
    dttime = num2date(nptime[tidx_start:tidx_end+1], units=t_units, calendar=t_cal)

    # truncate time to seconds
    ntime = tidx_end+1-tidx_start
    tdat = [dttime[i].isoformat(' ', 'seconds')
            for i in range(ntime)]

    # read cast number to get the indices in the full record
    cast = infile.variables['cast'][idx_loc]

    # indices in the full record
    idx_cast = cast[tidx_start:tidx_end+1]-1

    # read depth (limited to upper max_depth)
    depth = infile.variables['depth'][:]
    depth = abs(depth)
    idx_depth_max = np.searchsorted(depth, max_depth, side='left')+1
    ddat = -depth[:idx_depth_max]

    # get global missing value
    if 'missing_value' in attlist:
        gmvalue = infile.missing_value
    elif '_FillValue' in attlist:
        gmvalue = infile._FillValue
    else:
        # turn off auto mask, handled in write_pfl()
        infile.set_auto_mask(False)
        gmvalue = np.nan

    # read temperature and salinity
    np.warnings.filterwarnings('ignore')
    temp = infile.variables['Temperature'][idx_cast,:idx_depth_max]
    temp_qcf = infile.variables['TempFlag'][idx_cast,:idx_depth_max]
    temp[temp_qcf>0] = gmvalue
    salt = infile.variables['Salinity'][idx_cast,:idx_depth_max]
    salt_qcf = infile.variables['SalnFlag'][idx_cast,:idx_depth_max]
    salt[temp_qcf>0] = gmvalue

    # remove profiles with too many missing values near the surface
    # check the upper 100 m of the profile
    idx_depth_sl = np.searchsorted(depth, 100, side='left')
    temp_sl = temp[:,:idx_depth_sl+1]
    temp_sl[temp_sl==gmvalue] = np.NaN
    # number of profiles
    npfl = temp_sl.shape[0]
    # number of levels
    nlev = temp_sl.shape[1]
    # indices of profiles that have enough valid data
    idx_pass = []
    for i in np.arange(npfl):
        # number of NaNs in the profile
        nnan = np.count_nonzero(np.isnan(temp_sl[i,:]))
        if nnan < nlev/3:
            # ignore the profile if the number of missing value is greater
            # than 1/3 of the total value within the upper 100 m
            idx_pass.append(i)

    # skip if no valid profiles
    if len(idx_pass) < 1:
        # no message if dry run
        if not args.l_dry_run:
            print("Too many missing values in the profiles. Skip.")
        sys.exit(1)

    # updated indices in the full record
    idx_cast_new = idx_cast[idx_pass]

    # updated temperature and salinity profiles
    temp_avail = temp[idx_pass, :]
    salt_avail = salt[idx_pass, :]

    # write in file
    if l_single:
        # select the profile which has the median of near surface temperature
        # (averaged temperature between -10 m and -50 m)
        idx_depth_avg1 = np.searchsorted(depth, 10, side='left')
        idx_depth_avg2 = np.searchsorted(depth, 50, side='left')
        temp_smp = temp_avail[:,idx_depth_avg1:idx_depth_avg2+1]
        temp_smp[temp_smp==gmvalue] = np.NaN
        temp_avg = np.nanmean(temp_smp, axis=1)
        # find the index of the median
        idx_temp_median = np.argsort(temp_avg)[(len(temp_avg)-1)//2]
        # set the date to the starting date
        tdat_sgl = dt_start
        # write profiles
        if args.l_dry_run:
            # print("Number of profiles: {}".format(len(temp_avg)))
            # print("Date of output profile: {}".format(tdat[idx_temp_median]))
            # print("Longitude: {}".format(lon[idx_cast[idx_temp_median]]))
            # print("Latitude: {}".format(lat[idx_cast[idx_temp_median]]))
            print("{:s} {:6.2f} {:6.2f} {:3d} {:6.2f} {:6.2f} {:6.2f}".format(tdat[idx_temp_median],
                lon[idx_cast_new[idx_temp_median]], lat[idx_cast_new[idx_temp_median]],
                len(temp_avg), rlon, rlat, temp_avg[idx_temp_median]))
        else:
            write_pfl(fname_out_temp, [tdat_sgl], ddat, [temp_avail[[idx_temp_median],:]], mask=gmvalue)
            write_pfl(fname_out_salt, [tdat_sgl], ddat, [salt_avail[[idx_temp_median],:]], mask=gmvalue)
    else:
        # write all data
        if not args.l_dry_run:
            write_pfl(fname_out_temp, tdat, ddat, [temp_avail], mask=gmvalue)
            write_pfl(fname_out_salt, tdat, ddat, [salt_avail], mask=gmvalue)

if __name__ == "__main__":
    main()
