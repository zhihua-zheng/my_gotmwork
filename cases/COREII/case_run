#!/bin/bash
# Setup and run GOTM for CORE-II
# Loop over latitude and longitude
#
# This script essentially does the same thing as case_run_multi, but
# skips the step to preprocess the input data, which is now taken care
# of my preproc_data
#
# Qing Li, 20180503

#######################################################################
#                              Set path                               #
#######################################################################

# setup paths and tools
source "../../set_tools.sh"

# data directory for preprocessed input data
dataroot="${GOTMDATA_ROOT}/gotmdata_core2"

#######################################################################
#                           Set parameters                            #
#######################################################################

# name of the dataset
title="COREII"

# location
lat=-46
lon=226

# set max depth and levels, grid zooming at surface
maxdepth=500
nlev=100
ddu=0
ddl=0

# run parameters
dt=600
# set output frequency (3-hourly output)
let nsave=10800/dt

# output file name
outname="gotm_out"

# starting and ending date - in the format of YYYYMMDD
# the starting date should match what are available in the
# input data directory
datestart="20080601"
dateend="20090630"

# name of the turbulence model
turbmethod="KPP-CVMix"
# turbmethod="KPPLT-ENTR"
# turbmethod="OSMOSIS"
# turbmethod="EPBL"
# turbmethod="SMCLT"
# turbmethod="SMC"

# setup
dz=$((maxdepth/nlev))
setup="${title}_Local/VR${dz}m_DT${dt}s_${datestart}-${dateend}"

#######################################################################
#                         Loop over locations                         #
#######################################################################

# input data starting and ending date
inputstart="20080601"
inputend="20091231"

# input data folder name
inputname="${title}_LAT${lat}_LON${lon}_${inputstart}-${inputend}"

# check if data exists
if [ -d ${dataroot}/${inputname} ]; then

    # case name
    casename="${title}_LAT${lat}_LON${lon}"

    # print case name
    echo ${casename}

    # skip if initial temperature and salinity profiles are not available
    tprofdata=${dataroot}/${inputname}/tprof_file_${datestart}.dat
    sprofdata=${dataroot}/${inputname}/sprof_file_${datestart}.dat
    if [ -s ${tprofdata} -a -s ${sprofdata} ]; then
        # create run directory
        rundir="${GOTMRUN_ROOT}/${setup}/${turbmethod}/${casename}"
        mkdir -p ${rundir}
        cd ${rundir}

        # set up namelists
        cp ${nmldir}/*.nml ./

        # link input data
        ln -s ${dataroot}/${inputname}/*_file.dat ./
        tprof_name="tprof_file.dat"
        sprof_name="sprof_file.dat"
        ln -s ${tprofdata} ./${tprof_name}
        ln -s ${sprofdata} ./${sprof_name}
    else
        echo "Temperature or salinity profile not found. Skip."
        exit 1
    fi

    xmlfile=${title}.xml
    cp ${xmldir}/${xmlfile} ./
    sed -i.bk "s/_TAG_LAT/\"${lat}\"/g" ./${xmlfile}
    sed -i.bk "s/_TAG_LON/\"${lon}\"/g" ./${xmlfile}
    sed -i.bk "s/_TAG_MAXDEPTH/\"${maxdepth}\"/g" ./${xmlfile}

    # set run parameters
    ${cmd_case_preproc} -xml ${xmlfile} -root ${GOTMWORK_ROOT} \
    -ds ${datestart} -de ${dateend} -method nc2dat_latlon -skipdata
    ${cmd_nmlchange} -f gotmrun.nml -e title -v ${title}
    ${cmd_nmlchange} -f gotmrun.nml -e out_fn -v ${outname}
    ${cmd_nmlchange} -f gotmrun.nml -e dt -v ${dt}
    ${cmd_nmlchange} -f gotmrun.nml -e nsave -v ${nsave}
    ${cmd_nmlchange} -f gotmrun.nml -e nlev -v ${nlev}
    ${cmd_nmlchange} -f gotmrun.nml -e eq_state_method -v 4
    ${cmd_nmlchange} -f gotmmean.nml -e ddu -v ${ddu}
    ${cmd_nmlchange} -f gotmmean.nml -e ddl -v ${ddl}

    ${cmd_nmlchange} -f airsea.nml -e swr_method -v 2
    ${cmd_nmlchange} -f airsea.nml -e swr_file -v 'swr_file.dat'
    ${cmd_nmlchange} -f airsea.nml -e swr_factor -v 1

    # use meteo data instead of fluxes
    ${cmd_nmlchange} -f airsea.nml -e calc_fluxes -v .true.
    ${cmd_nmlchange} -f airsea.nml -e fluxes_method -v 2
    ${cmd_nmlchange} -f airsea.nml -e back_radiation_method -v 1

    # Stokes drift data
    ${cmd_nmlchange} -f obs.nml -e ustokes_method -v 3
    ${cmd_nmlchange} -f obs.nml -e nfreq -v 3
    ${cmd_nmlchange} -f obs.nml -e usp_file -v "usp_file.dat"

    # bulk wave parameter
    ${cmd_nmlchange} -f obs.nml -e wave_method -v 2
    ${cmd_nmlchange} -f obs.nml -e wave_file -v "wave_file.dat"

    # processing Argo data for initialization
    ${cmd_nmlchange} -f obs.nml -e t_prof_method -v 2
    ${cmd_nmlchange} -f obs.nml -e t_prof_file -v ${tprof_name}
    ${cmd_nmlchange} -f obs.nml -e s_prof_method -v 2
    ${cmd_nmlchange} -f obs.nml -e s_prof_file -v ${sprof_name}

    # set turbulence method
    source ${scpt_case_turbmethod}

    # turn off bottom boundary layer
    ${cmd_nmlchange} -f kpp.nml -e kpp_bbl -v .false.
    # calculate Langmuir number and enhancement factor from Stokes drift
    ${cmd_nmlchange} -f langmuir.nml -e langmuir_number_method -v 4

    # run GOTM
    ${cmd_gotm} 2> log.${outname}

fi # input exist

