#!/bin/bash
# Setup and run GOTM for CORE-II
# Loop over latitude and longitude
#
# This script essentially does the same thing as case_run_multi, but
# skips the step to preprocess the input data, which is now taken care
# of by preproc_data
#
# Qing Li, 20180503
#          20181104, named options

#######################################################################
#                           parse arguments                           #
#######################################################################
lon_start=2
lon_end=360
turbmethod="none"
date_start="none"
date_end="none"

while getopts l:L:m:d:D: options
do
    case $options in
        # starting longitude
        l) lon_start=$OPTARG ;;
        # ending longitude
        L) lon_end=$OPTARG ;;
        # turbulence model
        m) turbmethod=$OPTARG ;;
        # starting date
        d) date_start=$OPTARG ;;
        # ending date
        D) date_end=$OPTARG ;;
        \?) echo "Unknown option -$OPTARG"
            exit 1 ;;
    esac
done

if [[ ${turbmethod} == "none" ]]; then
    echo "Missing option -m [turbulence model]"
    exit 1
fi

if [[ ${date_start} == "none" ]]; then
    echo "Missing option -d [starting date in YYYYMMDD]"
    exit 1
fi

if [[ ${date_end} == "none" ]]; then
    echo "Missing option -D [ending date in YYYYMMDD]"
    exit 1
fi

#######################################################################
#                              Set path                               #
#######################################################################

# setup paths and tools
source "../../set_tools.sh"

# data directory for preprocessed input data
dataroot="${GOTMDATA_ROOT}/gotmdata_core2"

# current path
curdir=$(pwd)

#######################################################################
#                           Set parameters                            #
#######################################################################

# name of the dataset
title="COREII"

# set max depth and levels, grid zooming at surface
maxdepth=500
nlev=500
ddu=0
ddl=0

# run parameters
dt=600
# set output frequency (6-hourly output)
let nsave=21600/dt

# output file name
outname="gotm_out"

# setup
dz=$((maxdepth/nlev))
setup="${title}_Global/VR${dz}m_DT${dt}s_${date_start}-${date_end}"

#######################################################################
#                         Loop over locations                         #
#######################################################################
dlon=4
lat_start=-70
lat_end=70
dlat=4

# input data starting and ending date
inputstart="20080601"
inputend="20091231"

# start outer loop over lon
lon=${lon_start}
while [[ ${lon} -le ${lon_end} ]]; do
# start inner loop over lat
lat=${lat_start}
while [[ ${lat} -le ${lat_end} ]]; do

    # input data folder name
    inputname="${title}_LAT${lat}_LON${lon}_${inputstart}-${inputend}"

    # check if data exists
    if [[ -d ${dataroot}/${inputname} ]]; then

        # case name
        casename="${title}_LAT${lat}_LON${lon}"

        # print case name
        echo ${casename}

        # skip if initial temperature and salinity profiles are not available
        tprofdata=${dataroot}/${inputname}/tprof_file_${date_start}.dat
        sprofdata=${dataroot}/${inputname}/sprof_file_${date_start}.dat
        if [[ -s ${tprofdata} ]] && [[ -s ${sprofdata} ]]; then
            # create run directory
            rundir="${GOTMRUN_ROOT}/${setup}/${turbmethod}/${casename}"
            mkdir -p ${rundir}
            cd ${rundir}

            # set up namelists
            cp ${nmldir}/*.nml ./

            # link input data
            ln -sf ${dataroot}/${inputname}/*_file.dat ./
            tprof_name="tprof_file.dat"
            sprof_name="sprof_file.dat"
            ln -sf ${tprofdata} ./${tprof_name}
            ln -sf ${sprofdata} ./${sprof_name}
        else
            echo "Temperature or salinity profile not found. Skip."
            lat=$((${lat}+${dlat}))
            continue
        fi

        xmlfile=${title}.xml
        cp ${xmldir}/${xmlfile} ./
        sed -i.bk "s/_TAG_LAT/\"${lat}\"/g" ./${xmlfile}
        sed -i.bk "s/_TAG_LON/\"${lon}\"/g" ./${xmlfile}
        sed -i.bk "s/_TAG_MAXDEPTH/\"${maxdepth}\"/g" ./${xmlfile}

        # set run parameters
        ${cmd_case_preproc} -xml ${xmlfile} -root ${GOTMWORK_ROOT} \
        -ds ${date_start} -de ${date_end} -method nc2dat_latlon -skipdata
        ${cmd_nmlchange} -f gotmrun.nml -e title -v ${title}
        ${cmd_nmlchange} -f gotmrun.nml -e out_fn -v ${outname}
        ${cmd_nmlchange} -f gotmrun.nml -e dt -v ${dt}
        ${cmd_nmlchange} -f gotmrun.nml -e nsave -v ${nsave}
        ${cmd_nmlchange} -f gotmrun.nml -e nlev -v ${nlev}
        ${cmd_nmlchange} -f gotmrun.nml -e eq_state_method -v 4
        ${cmd_nmlchange} -f gotmmean.nml -e ddu -v ${ddu}
        ${cmd_nmlchange} -f gotmmean.nml -e ddl -v ${ddl}

        ${cmd_nmlchange} -f airsea.nml -e swr_method -v 2
        ${cmd_nmlchange} -f airsea.nml -e swr_file -v 'swr_file.dat'
        ${cmd_nmlchange} -f airsea.nml -e swr_factor -v 1

        # use meteo data instead of fluxes
        ${cmd_nmlchange} -f airsea.nml -e calc_fluxes -v .true.
        ${cmd_nmlchange} -f airsea.nml -e fluxes_method -v 2
        ${cmd_nmlchange} -f airsea.nml -e back_radiation_method -v 1

        # Stokes drift data
        ${cmd_nmlchange} -f obs.nml -e ustokes_method -v 3
        ${cmd_nmlchange} -f obs.nml -e nfreq -v 3
        ${cmd_nmlchange} -f obs.nml -e usp_file -v "usp_file.dat"

        # bulk wave parameter
        ${cmd_nmlchange} -f obs.nml -e wave_method -v 2
        ${cmd_nmlchange} -f obs.nml -e wave_file -v "wave_file.dat"

        # processing Argo data for initialization
        ${cmd_nmlchange} -f obs.nml -e t_prof_method -v 2
        ${cmd_nmlchange} -f obs.nml -e t_prof_file -v ${tprof_name}
        ${cmd_nmlchange} -f obs.nml -e s_prof_method -v 2
        ${cmd_nmlchange} -f obs.nml -e s_prof_file -v ${sprof_name}

        # set turbulence method
        source ${scpt_case_turbmethod}

        # turn off bottom boundary layer
        ${cmd_nmlchange} -f kpp.nml -e kpp_bbl -v .false.
        # calculate Langmuir number and enhancement factor from Stokes drift
        ${cmd_nmlchange} -f langmuir.nml -e langmuir_number_method -v 4

        # run GOTM
        ${cmd_gotm} 2> log.${outname}

        # post-processing data
        # extract variables from gotm output data
        source ${curdir}/case_postproc.sh

    fi # input exist

# end inner loop over lat
lat=$((${lat}+${dlat}))
done
# end outer loop over lon
lon=$((${lon}+${dlon}))
done

